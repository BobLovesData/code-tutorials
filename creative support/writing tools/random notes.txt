


plotly/altair/bokeh + plotly-dash/streamlit

Create hyperperameter tuning lecture.

https://discord.gg/enfDGUH

Netlify
HoneyBadger.io
MDM: https://maxbachmann.github.io/RapidFuzz/index.html


Python tutorial todos
Add more examples to making decisions
In lesson 20 example one, explain more about breaking down URIs. Actually make a whole example that is just that.cross platform code.
In database set up, add instructions on creating the Proxy Account.
Improve the code wars page in the preflight
In lesson 15 give an example of how you would ahve to write somthign out without namespaces.
Line numbers in lesson 16 don't show in html. Figure out how to show line numbers in HTML.
In lesson 17, write an explanation of how to make an anamous function with lamba.
In Lesson 26 put some explanation in basic picle ops
In the prefight section, change anchor tags so they all open in a new tab.
Add actual instructions to creating a DSN instead of links.
convert examples into pyton scripts.
Fix the header in logical operators https://tutorials.massstreetuniversity.com/python/basics/07-making-decisions.html
Fix headers in synonyms https://tutorials.massstreetuniversity.com/python/basics/07-making-decisions.html


Object Oriented Programming 101
In data types talk about how everything is an object. Object = Data Type = Class

Prelanch task
meta tags*




Take a look at using zapier instead of thinkific pro plus

FW Docs todos:

In Table Anatomy and in code in sample table scripts, make sure all SQL is capitalized. Make sure that these scripts have doc blocks.
All hashing columns should NOT be var anything.
Double check all code for consistancy. All find and replace values should be the same.
	Use YourEDW
	DimYourDimensionName
	FactYourFactTableName
	Usage vs whatever else in the doc block
Replace author in code block with -- Engineer:
move all drop indexes to the top of the script.
Replace tutorials with actaul text.
When you do examples, go back to the tool and fill it in then drop that code in the section that talks about that tab. 
Create two scipts. One that populates config from table and one from YAML file.
Further flesh out the OLTP to OLAP section
Update all processes to check for IsProcessed and all binary columns.
Explain why temporal tables suck.
Fleshout create Data source name 
Draw diagram for fact table load.
Do we need to get rid of CR LF when we load data with BULK INSERT?
Change python errors to:
except Exception as e:
    print(e)
In python code, fix archive.close() add parin
Fix comment in QueryDatabaseAndWriteSmallFile #bulk load txt file to SQL Server
add os.chdir(source_path) to zip processes.
Remove references to specific systems.
https://etl-framework.massstreetuniversity.com/data-warehouse-etl-framework/untitled-1/sql/table-object-sample-scripts/sample-fact-table.sql
	change the name of the constraint so it can be replaced.
Change log
auto de allocate batching cursors -	https://stackoverflow.com/questions/8737586/tsql-cursor-how-to-check-if-already-declared-and-thus-deallocate
Add academic version (do this dead last!)

For python ds tutorial saving objects with pickle
C:\Users\Bob\OneDrive\Documents\Extensive Enterprises\Mass Street Analytics\Projects\Viracore\Historical Code\Python Projects\TNP

For SQL tutorial and framework


Hashing varchar(max)
Quick thoughts;
The HASHBYTES has the 8000 and 4000 character limits for VARCHAR and NVARCHAR data types respectfully. This means that if one wants to create a hash of character strings larger than the limit then one has either to resort to external methods (CLR etc.) or chunk the string accordingly. I have done this in T-SQL by using the following method:
1) Chop the string into 8000/4000 characters
2) Hash each chunk
3) Concatenate the hashes and test for the length
4) Hash the concatenation, repeating the chopping if longer than the limit.
5) Finally ending up with one hash.
This will generate a unique hash for the character string but obviously it will not match other methods which process the whole string in one go.
The length of the output has nothing to do with the input lenght, it depends on which algorithm is used, available algorithms are MD2, MD4, MD5, SHA, SHA1, SHA2_256 and SHA2_512. There is a performance difference between those and I've found that the SHA1 is normally the fastest and MD5 is close behind.
For several reasons I'm not to keen on a calculated column for the hashes, performance being an obvious one, I rather hash the content on the insert.


count distinct on more than one column
Masking values: As RIGHT('000000000' + LTRIM(RTRIM(dnpd.valueFld)),9) AS SalesAgentNumber,
Lesson 30. Variables rename Example Declaring A Variable And Setting Its Value In One Line Of Code to Declaring A Default Value
Fix the log an issue GitHub link.


https://tutorials.massstreetuniversity.com/transact-sql/basic/string-functions.html Fix the typos on all the Lets in the tables. Should be Let's




For capstone DE course: https://github.com/oleg-agapov/data-engineering-book/blob/master/book/2-beginner-path/2-1-databases/databases.md

Python testing style guide https://blog.thea.codes/my-python-testing-style-guide/


Syllabus update notes: Update the sample download database page.
Finish the lecture schedule up to unit two.


































